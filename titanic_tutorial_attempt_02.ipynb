{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain = pd.read_csv('/kaggle/input/titanic-competition/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic-competition/test.csv')\njoined = pd.concat([train.drop('Survived', axis=1), test])\nprint(joined.shape)\n\ntrain.isnull().sum()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T03:54:32.621318Z","iopub.execute_input":"2023-10-31T03:54:32.621719Z","iopub.status.idle":"2023-10-31T03:54:32.656321Z","shell.execute_reply.started":"2023-10-31T03:54:32.621689Z","shell.execute_reply":"2023-10-31T03:54:32.654961Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stdout","text":"(1309, 11)\n","output_type":"stream"},{"execution_count":204,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from scipy.stats import pearsonr\nfrom pandas.api.types import is_numeric_dtype\nimport re\n\njoined2, train2, test2 = joined.copy(), train.copy(), test.copy()\n\n# Get titles and fare first, since we will use them to impute age\ncommon_titles = ['Mr', 'Mrs', 'Miss', 'Master', 'Doctor', 'Rev']\ndef get_titles_and_fare(df):\n    df['Fare'] = df['Fare'].fillna(joined2['Fare'].mean())\n    df['FareRank'] = df['Fare'].rank()\n    for title in common_titles:\n        df[title] = df['Name'].apply(lambda x: 1 if title == x.split(', ')[1].split('. ')[0] else 0)\n    return df\n\njoined2 = get_titles_and_fare(joined2)\ntrain2 = get_titles_and_fare(train2)\ntest2 = get_titles_and_fare(test2)\n\n# Create groupby objects for imputing age\ntitle_gs = [joined2.groupby(['Pclass', title])['Age'] for title in common_titles]\nclass_g = joined2.groupby('Pclass')['Age']\n\ndef process_features(df):\n    def impute_age(row):\n        if np.isnan(row['Age']):\n            row['Age'] = class_g.get_group(row['Pclass']).agg('mean')\n            for i, title in enumerate(common_titles):\n                if row[title] == 1:\n                    row['Age'] = title_gs[i].get_group((row['Pclass'], 1)).agg('mean')\n        return row\n    df = df.apply(impute_age, axis=1)\n    df['Wife'] = df['Name'].apply(lambda x: 1 if re.search(r\"\\(.+\\)\", x) else 0)\n    df['Embarked'] = df['Embarked'].fillna('S').apply(lambda x: ['S', 'C', 'Q'].index(x))\n    df['Sex'] = df['Sex'].apply(lambda x: 0 if x == 'male' else 1)\n    df['Cabin Mates'] = df.groupby('Cabin')['Cabin'].transform('count').fillna(0)\n    df['Cabin'] = df['Cabin'].fillna(0).apply(lambda x: x if x == 0 else ord(x[0]) - 64)\n    df['Fam'] = df['Parch'] + train_df['SibSp']\n    return df\n\ntrain2 = process_features(train2)\ntest2 = process_features(test2)\ntest2.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:54:35.532812Z","iopub.execute_input":"2023-10-31T03:54:35.533279Z","iopub.status.idle":"2023-10-31T03:54:36.624466Z","shell.execute_reply.started":"2023-10-31T03:54:35.533242Z","shell.execute_reply":"2023-10-31T03:54:36.623392Z"},"trusted":true},"execution_count":205,"outputs":[{"execution_count":205,"output_type":"execute_result","data":{"text/plain":"PassengerId    0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nCabin          0\nEmbarked       0\nFareRank       0\nMr             0\nMrs            0\nMiss           0\nMaster         0\nDoctor         0\nRev            0\nWife           0\nCabin Mates    0\nFam            0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\n\ntrain3 = train2.copy()\ntest3 = test2.copy()\n\ncols = ['Pclass', 'Fam', 'Parch', \n        'SibSp', 'Age',\n        'FareRank', 'Cabin Mates',\n       'Sex', \n       'Embarked']\n\nX = train3[cols]\nX_test = test3[cols]\nX = scaler.fit_transform(X)\nscaler = StandardScaler()\nX_test = scaler.fit_transform(X_test)\ny = train3['Survived']","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:58:05.536052Z","iopub.execute_input":"2023-10-31T05:58:05.536470Z","iopub.status.idle":"2023-10-31T05:58:05.561784Z","shell.execute_reply.started":"2023-10-31T05:58:05.536438Z","shell.execute_reply":"2023-10-31T05:58:05.560364Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport warnings\n\n# warnings.filterwarnings('ignore')\n\nmodels = [\n    {\n        'name': 'Random Forest',\n        'model': RandomForestClassifier(),\n        'params': {'max_depth': [2, 5, 10],\n          'min_samples_leaf': [3, 4],\n         'n_estimators': [100, 150]}\n    },\n    {\n        'name': 'Gradient Boosting',\n        'model': GradientBoostingClassifier(),\n        'params': {'n_estimators': [100],  \n              'max_depth': [5], \n              'min_samples_leaf': [5],\n              'learning_rate': [.001, .01, .1, 1],\n             'subsample': [.5]} \n    },\n#     {\n#         'name': 'Logistic Regression',\n#         'model': LogisticRegression(max_iter=10000),\n#         'params': {'penalty': [None, 'l2'], \n#           'C': [.5, 1, 2]}\n#     },\n#     {\n#         'name': 'Linear Support Vector Machine',\n#         'model': LinearSVC(max_iter=100000, dual=True),\n#         'params': {'penalty': ['l2', 'l1'], \n#           'loss': ['hinge', 'hinge_squared'],\n#           'C': [.01, .1, 1]}\n#     },\n#     {\n#         'name': 'Support Vector Machine',\n#         'model': SVC(),\n#         'params': {'C': [100, 200, 500],  \n#               'gamma': [.1, .03], \n#               'kernel': ['rbf']}\n#     }\n]\nfor model in models:\n    print('Model:', model['name'])\n    gs = GridSearchCV(estimator=model['model'],\n                      param_grid=model['params'],\n                      verbose=True, cv=5,\n                      scoring='accuracy')\n    gs.fit(X, y)\n    results = gs.cv_results_\n    print('Best Score:', gs.best_score_, 'Best Params:', gs.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:33:00.956772Z","iopub.execute_input":"2023-10-31T05:33:00.957454Z","iopub.status.idle":"2023-10-31T05:33:24.845488Z","shell.execute_reply.started":"2023-10-31T05:33:00.957418Z","shell.execute_reply":"2023-10-31T05:33:24.844338Z"},"trusted":true},"execution_count":272,"outputs":[{"name":"stdout","text":"Model: Random Forest\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest Score: 0.8294017952419811 Best Params: {'max_depth': 5, 'min_samples_leaf': 3, 'n_estimators': 150}\nModel: Gradient Boosting\nFitting 5 folds for each of 4 candidates, totalling 20 fits\nBest Score: 0.8417362375243236 Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 100, 'subsample': 0.5}\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.ensemble import StackingClassifier\nfrom lightgbm import LGBMClassifier\n# Combine models\n\nrf_clf = RandomForestClassifier(max_depth=55, min_samples_leaf=3, n_estimators=150, random_state=0)\nlog_reg = LogisticRegression(max_iter=10000, C=1, penalty='l2', random_state=0)\nsv_clf = SVC(C=100, gamma=.03, kernel='rbf', probability=True)\ngb_clf = GradientBoostingClassifier(max_depth=5, min_samples_leaf=5, n_estimators=100, learning_rate=.1, subsample=.5, random_state=0)\nlgbm_clf = LGBMClassifier(random_state=10)\nst_clf = StackingClassifier(\n    estimators=[\n        ('lr', LogisticRegression(max_iter=10000, C=1, penalty='l2', random_state=0)),\n        ('gb', GradientBoostingClassifier(max_depth=5, min_samples_leaf=5, n_estimators=100, learning_rate=.01, subsample=.5, random_state=0)),\n        ('rf', RandomForestClassifier(max_depth=15, min_samples_leaf=3, n_estimators=150, random_state=0)),\n        ('svc', SVC(C=100, gamma=.03, kernel='rbf', probability=True))\n    ],\n    final_estimator=LogisticRegression(max_iter=10000, C=1, penalty='l2', random_state=0), cv=3\n)\n\nlog_reg.fit(X, y)\nsv_clf.fit(X, y)\ngb_clf.fit(X, y)\nst_clf.fit(X, y)\nrf_clf.fit(X, y)\nlgbm_clf.fit(X, y)\n\n# y_pred_lr = log_reg.predict(X)\n# y_pred_svc = sv_clf.predict(X)\n# y_pred_lr_proba = log_reg.predict_proba(X)\n# y_pred_svc_proba = sv_clf.predict_proba(X)\n# y_pred_weighted = (y_pred_lr_proba[:,1] + y_pred_svc_proba[:,1]) // 1\ny_pred_stacked = st_clf.predict(X)\ny_pred_gb = gb_clf.predict(X)\ny_pred_rf = rf_clf.predict(X)\ny_pred_lgbm = lgbm_clf.predict(X)\n\nlr = log_reg.predict(X_test)\nsv = sv_clf.predict(X_test)\ngb = gb_clf.predict(X_test)\nrf = rf_clf.predict(X_test)\nlgbm = lgbm_clf.predict(X_test)\n\ny_final_predict = (lr + sv + gb + rf + lgbm) // 3\n\n# print('Logreg model:')\n# print(confusion_matrix(y_pred_lr, y))\n# print(accuracy_score(y_pred_lr, y))\n# print('SVC model:')\n# print(confusion_matrix(y_pred_svc, y))\n# print(accuracy_score(y_pred_svc, y))\n# print('Weighted model:')\n# print(confusion_matrix(y_pred_weighted, y))\n# print(accuracy_score(y_pred_weighted, y))\nprint('Stacked model:')\nprint(confusion_matrix(y_pred_stacked, y))\nprint(accuracy_score(y_pred_stacked, y))\nprint('Gradient Boosted model:')\nprint(confusion_matrix(y_pred_gb, y))\nprint(accuracy_score(y_pred_gb, y))\nprint('Random Forest model:')\nprint(confusion_matrix(y_pred_rf, y))\nprint(accuracy_score(y_pred_rf, y))\nprint('LGBM model:')\nprint(confusion_matrix(y_pred_lgbm, y))\nprint(accuracy_score(y_pred_lgbm, y))\ny_final_predict","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:58:13.667004Z","iopub.execute_input":"2023-10-31T05:58:13.668556Z","iopub.status.idle":"2023-10-31T05:58:18.453521Z","shell.execute_reply.started":"2023-10-31T05:58:13.668506Z","shell.execute_reply":"2023-10-31T05:58:18.452367Z"},"trusted":true},"execution_count":282,"outputs":[{"name":"stdout","text":"Stacked model:\n[[513  75]\n [ 36 267]]\n0.8754208754208754\nGradient Boosted model:\n[[529  46]\n [ 20 296]]\n0.9259259259259259\nRandom Forest model:\n[[526  60]\n [ 23 282]]\n0.9068462401795735\nLGBM model:\n[[537  24]\n [ 12 318]]\n0.9595959595959596\n","output_type":"stream"},{"execution_count":282,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_final_predict})\noutput.to_csv('submission16.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:58:38.000446Z","iopub.execute_input":"2023-10-31T05:58:38.000847Z","iopub.status.idle":"2023-10-31T05:58:38.009665Z","shell.execute_reply.started":"2023-10-31T05:58:38.000817Z","shell.execute_reply":"2023-10-31T05:58:38.008441Z"},"trusted":true},"execution_count":283,"outputs":[]}]}